# CRAWLER RETS

Este repositÃ³rio contÃ©m um crawler leve para coletar notÃ­cias relacionadas Ã  saÃºde pÃºblica, cooperaÃ§Ã£o internacional e formaÃ§Ã£o tÃ©cnica em saÃºde, com base no perfil da RETS (Rede Internacional de EducaÃ§Ã£o de TÃ©cnicos em SaÃºde).

## ğŸ” O que o script faz

- Varre sites definidos em um CSV (RETS_reorganizado.csv)
- Busca por palavras-chave relevantes (ex: cooperaÃ§Ã£o, formaÃ§Ã£o, OPAS, OMS)
- Salva os resultados em `matches_rets.csv`

## ğŸš€ ExecuÃ§Ã£o automÃ¡tica (GitHub Actions)
O crawler roda automaticamente toda segunda-feira Ã s 3h (UTC).  
VocÃª tambÃ©m pode executar manualmente via GitHub Actions â†’ "Run workflow".

## â–¶ï¸ Como usar localmente

1. Clone o repositÃ³rio
2. Instale as dependÃªncias:
   ```bash
   pip install -r requirements.txt
   ```
3. Execute:
   ```bash
   python scan_rets.py
   ```

## ğŸ§ª Arquivos principais

- `scan_rets.py`: cÃ³digo do crawler
- `RETS_reorganizado.csv`: base de sites a visitar (vocÃª deve adicionar esse arquivo)
- `matches_rets.csv`: resultados salvos
- `.github/workflows/crawl.yml`: agendamento no GitHub Actions

---
Desenvolvido para monitoramento automatizado com base no perfil editorial da RETS.
